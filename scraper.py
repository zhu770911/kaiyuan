import os
import time
import pandas as pd
from github import Github, Auth, RateLimitExceededException
from datetime import datetime

# --- 1. é…ç½®åŒºåŸŸ ---
TOKEN = os.getenv("GITHUB_TOKEN")
if not TOKEN:
    print("âš ï¸  è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ GITHUB_TOKEN")
    TOKEN = input("ğŸ‘‰ è¯·æ‰‹åŠ¨è¾“å…¥ Token: ").strip()

REPO_NAME = "django/django"   # ç›®æ ‡ä»“åº“
MAX_ISSUES = 500              # å»ºè®®å…ˆè®¾ä¸º 200ï¼Œä¿è¯å¿«é€Ÿå‡ºç»“æœ
CORE_LIMIT = 20               # è¯†åˆ«å‰ 20 åæ ¸å¿ƒæˆå‘˜

def save_to_csv(data_list):
    if not data_list:
        print("âš ï¸ æ²¡æœ‰æ”¶é›†åˆ°æ•°æ®ï¼Œè·³è¿‡ä¿å­˜ã€‚")
        return
    df = pd.DataFrame(data_list)
    os.makedirs('data', exist_ok=True)
    save_path = "data/django_bugs_analysis.csv"
    df.to_csv(save_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {save_path}")
    print(f"ğŸ“Š æœ€ç»ˆæ”¶é›†è¡Œæ•°: {len(df)}")

def get_bug_data():
    auth = Auth.Token(TOKEN)
    g = Github(auth=auth)
    
    try:
        repo = g.get_repo(REPO_NAME)
        print(f"ğŸ”— å·²è¿æ¥åˆ°ä»“åº“: {REPO_NAME}")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return []

    # --- 2. è¯†åˆ«æ ¸å¿ƒæˆå‘˜ ---
    print("ğŸ•µï¸  æ­£åœ¨è¯†åˆ«æ ¸å¿ƒè´¡çŒ®è€…...")
    contributors = repo.get_contributors()
    core_members = [c.login for c in contributors[:CORE_LIMIT]]
    print(f"âœ… æ ¸å¿ƒæˆå‘˜åå•: {core_members}")

    # --- 3. æŠ“å–å¾ªç¯ ---
    print(f"ğŸš€ å¼€å§‹æ‰«æ (å°†åŒ…å« PR ä»¥è·å–æœ‰æ•ˆä¿®å¤æ•°æ®)...")
    
    # è·å–æœ€è¿‘æ›´æ–°çš„å·²å…³é—­è®°å½•
    issues = repo.get_issues(state='closed', sort='updated', direction='desc')
    
    bug_data = []
    scanned_count = 0
    
    try:
        for issue in issues:
            scanned_count += 1
            
            # å¿ƒè·³æç¤º
            if scanned_count % 50 == 0:
                print(f"running... [æ‰«æ: {scanned_count} | æ”¶é›†: {len(bug_data)}] ...")

            if len(bug_data) >= MAX_ISSUES:
                break
            
            # --- Django ä¸“å±åˆ¤å®šé€»è¾‘ ---
            title_lower = issue.title.lower()
            labels = [l.name.lower() for l in issue.labels]
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºä¿®å¤ç±»ä»»åŠ¡ï¼šæ ‡é¢˜å« fix/bug/regression æˆ–æ ‡ç­¾å« bug
            is_fix = (
                'fix' in title_lower or 
                'bug' in title_lower or 
                'fixed' in title_lower or
                any('bug' in lab for lab in labels)
            )
            
            if not is_fix:
                continue 

            # 4. æå–æ•°æ®
            # ä¼˜å…ˆè·å–æäº¤è€… (PR çš„ä½œè€…)ï¼Œå¦‚æœæ²¡æœ‰åˆ™å–å…³é—­è€…
            fixer = issue.user.login if issue.user else "Unknown"
            
            created = issue.created_at
            closed = issue.closed_at
            if not closed: continue

            duration = (closed - created).total_seconds() / 86400

            bug_data.append({
                "issue_id": issue.number,
                "type": "PR" if issue.pull_request else "Issue",
                "title": issue.title[:50],
                "duration_days": round(duration, 2),
                "comments_count": issue.comments,
                "fixer_login": fixer,
                "is_core_member": 1 if fixer in core_members else 0,
                "created_at": created.strftime('%Y-%m-%d')
            })

    except KeyboardInterrupt:
        print("\nğŸ›‘ æ‰‹åŠ¨åœæ­¢ï¼Œæ­£åœ¨ä¿å­˜...")
    except RateLimitExceededException:
        print("ğŸ›‘ è§¦å‘é™é€Ÿï¼Œè¯·ç¨åå†è¯•æˆ–æ›´æ¢ Tokenã€‚")
    
    return bug_data

if __name__ == "__main__":
    start_time = time.time()
    data = get_bug_data()
    save_to_csv(data)
    print(f"â±ï¸ æ€»è€—æ—¶: {round(time.time() - start_time, 2)} ç§’")